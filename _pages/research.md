---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

## Intermediate Level Adversarial Attack for Enhanced Transferability
In September, I joined the Cornell Undergrad Vision and Learning, a student-led research group aiming at conducting independent research that results in publication at top CV conferences. And for these 4 months I have been studying adversarial attacks agains neural networks, and we will submit it for ICML in January. 
We modified FGSM’s algorithm to generate examples by going down along the loss direction of each layer of a source model instead of the only the final layer's, and found the black-box attack transferability was maximized when we target at a certain intermediate layer. This shed light on network’s interpretability since we think this phenomenon is related to the information flow/feature hierarchy of a model.
<br/>
paperurl: https://arxiv.org/pdf/1811.08458.pdf 
 


